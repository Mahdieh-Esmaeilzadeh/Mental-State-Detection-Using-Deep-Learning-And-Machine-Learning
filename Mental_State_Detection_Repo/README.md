# Mental State Detection from Speech

This project focuses on **detecting mental and emotional states from human speech** using
Machine Learning (ML) and Deep Learning (DL) approaches.

## Features
- ğŸ™ï¸ **Speech Emotion Recognition (SER):** Detecting emotions from audio signals.
- ğŸ§ª **Feature Extraction:** MFCCs, spectral features, zero-crossing rate, RMS, pitch.
- ğŸ”„ **Data Augmentation:** Pitch shifting, noise injection, time-stretching, shifting.
- ğŸ¤– **Models Implemented:** 
  - Random Forest (baseline)
  - Multi-layer Perceptron (MLP)
  - Deep learning models (CNN, RNN, GRU, Dual-channel CNN-SSAE, Bimodal fusion)
- ğŸ“Š **Evaluation Metrics:** Confusion matrix, ROC curve, accuracy, F1-score.
- ğŸ“š **Documentation:** Literature review, thesis chapters, experiment reports.

## Repo Structure
- `data/` â†’ raw & processed datasets (e.g., IEMOCAP, SAVEE, EMODB).
- `notebooks/` â†’ Colab/Jupyter notebooks for training & experiments.
- `src/` â†’ core source code (data loading, features, models, training, evaluation).
- `experiments/` â†’ logs, trained models, visualizations, reports.
- `docs/` â†’ project proposal, literature review, thesis documentation.

## Usage
```bash
pip install -r requirements.txt
