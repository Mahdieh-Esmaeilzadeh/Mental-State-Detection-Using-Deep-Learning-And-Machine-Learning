{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Advanced Notebook\n",
    "\n",
    "Advanced pipeline for **Mental State Detection from Speech** using:\n",
    "- Dual-channel spectrogram input (Mel + IMel)\n",
    "- Data augmentation (hooks provided)\n",
    "- CNN + GRU hybrid model\n",
    "- Keras training with callbacks, model saving, and evaluation\n",
    "\n",
    "Notes:\n",
    "- Adjust `DATA_PATH` to point to `data/processed` or your spectrogram folder.\n",
    "- This notebook expects `.wav` files organized under `DATA_PATH/<label>/*.wav`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, math, warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Parameters & Paths — adjust to your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/processed\"   # change if needed\n",
    "SR = 16000\n",
    "N_MELS = 64\n",
    "WIN_LENGTH = 1024\n",
    "HOP_LENGTH = 512\n",
    "DURATION = 4.0    # seconds: trim/pad to this\n",
    "SAMPLES = int(SR * DURATION)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40\n",
    "MODEL_DIR = \"experiments/models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Helpers: load audio, trim/pad, augmentation hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_fixed(path, sr=SR, samples=SAMPLES):\n",
    "    y, _ = librosa.load(path, sr=sr)\n",
    "    # trim or pad\n",
    "    if len(y) > samples:\n",
    "        start = np.random.randint(0, len(y) - samples + 1)\n",
    "        y = y[start:start+samples]\n",
    "    else:\n",
    "        y = np.pad(y, (0, max(0, samples - len(y))), mode='constant')\n",
    "    return y\n",
    "\n",
    "def augment_audio_hook(y, sr=SR):\n",
    "    # Hook for augmentation (apply randomly when building dataset)\n",
    "    fn = random.choice(['none', 'pitch', 'stretch', 'noise', 'shift'])\n",
    "    if fn == 'pitch':\n",
    "        return librosa.effects.pitch_shift(y, sr, n_steps=random.uniform(-2,2))\n",
    "    if fn == 'stretch':\n",
    "        rate = random.uniform(0.9, 1.1)\n",
    "        try:\n",
    "            return librosa.effects.time_stretch(y, rate)\n",
    "        except Exception:\n",
    "            return y\n",
    "    if fn == 'noise':\n",
    "        noise_amp = 0.005 * np.random.uniform() * np.max(np.abs(y))\n",
    "        return y + noise_amp * np.random.normal(size=y.shape)\n",
    "    if fn == 'shift':\n",
    "        shift = int(random.uniform(-0.1, 0.1) * sr)\n",
    "        return np.roll(y, shift)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Spectrogram functions — Mel + IMel (IMel = Mel filterbank reversed to emphasize high freq)\n",
    "\n",
    "We compute standard Mel-spectrogram and an IMel spectrogram by applying a reversed Mel filterbank to the power spectrogram. Both are log-compressed and resized to the same shape for model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mel_spectrogram(y, sr=SR, n_mels=N_MELS, n_fft=WIN_LENGTH, hop_length=HOP_LENGTH):\n",
    "    S = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    S_power = np.abs(S)**2\n",
    "    mel_fb = librosa.filters.mel(sr=sr, n_fft=n_fft, n_mels=n_mels)\n",
    "    mel_spec = np.dot(mel_fb, S_power)\n",
    "    mel_db = librosa.power_to_db(mel_spec)\n",
    "    return mel_db\n",
    "\n",
    "def make_imel_spectrogram(y, sr=SR, n_mels=N_MELS, n_fft=WIN_LENGTH, hop_length=HOP_LENGTH):\n",
    "    # inverse emphasis mel: create mel filters and flip them to emphasize higher bins\n",
    "    S = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    S_power = np.abs(S)**2\n",
    "    mel_fb = librosa.filters.mel(sr=sr, n_fft=n_fft, n_mels=n_mels)\n",
    "    imel_fb = mel_fb[::-1, :]\n",
    "    imel_spec = np.dot(imel_fb, S_power)\n",
    "    imel_db = librosa.power_to_db(imel_spec)\n",
    "    return imel_db\n",
    "\n",
    "def normalize_spectrogram(spec):\n",
    "    # per-example normalization to 0-1\n",
    "    spec = spec - spec.min()\n",
    "    if spec.max() > 0:\n",
    "        spec = spec / spec.max()\n",
    "    return spec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Build dataset (spectrogram pairs) — careful with memory; use a generator for big datasets\n",
    "Below we build arrays directly for simplicity. For large datasets implement `tf.data.Dataset` or a Keras generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_spectrogram_dataset(data_path=DATA_PATH, augment=False, max_files_per_label=None):\n",
    "    X = []  # will hold (n_mels, frames, 2) arrays\n",
    "    y = []\n",
    "    labels = sorted([d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))])\n",
    "    for label in labels:\n",
    "        files = glob(os.path.join(data_path, label, \"*.wav\"))\n",
    "        if max_files_per_label:\n",
    "            files = files[:max_files_per_label]\n",
    "        for f in files:\n",
    "            y_audio = load_audio_fixed(f)\n",
    "            if augment and random.random() < 0.5:\n",
    "                y_audio = augment_audio_hook(y_audio)\n",
    "            mel = make_mel_spectrogram(y_audio)\n",
    "            imel = make_imel_spectrogram(y_audio)\n",
    "            # resize or pad frames to fixed width\n",
    "            # ensure same frames dimension\n",
    "            min_frames = min(mel.shape[1], imel.shape[1])\n",
    "            mel = mel[:, :min_frames]\n",
    "            imel = imel[:, :min_frames]\n",
    "            # normalize\n",
    "            mel = normalize_spectrogram(mel)\n",
    "            imel = normalize_spectrogram(imel)\n",
    "            pair = np.stack([mel, imel], axis=-1)  # shape: (n_mels, frames, 2)\n",
    "            X.append(pair.astype('float32'))\n",
    "            y.append(label)\n",
    "    X = np.array(X)\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "    return X, y_enc, le\n",
    "\n",
    "# Build dataset (small subset for example) — remove max_files_per_label or increase for real training\n",
    "X, y, label_encoder = build_spectrogram_dataset(DATA_PATH, augment=True, max_files_per_label=200)\n",
    "print('X shape:', X.shape, 'y shape:', y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Prepare inputs for Keras: transpose to channels-last and optionally resize frames\n",
    "Keras expects `(batch, height, width, channels)` where we choose `height = n_mels`, `width = frames`, `channels = 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally resize to fixed width (frames) for consistent shapes.\n",
    "def pad_frames(X, target_width=None):\n",
    "    if target_width is None:\n",
    "        # choose median width\n",
    "        widths = [x.shape[1] for x in X]\n",
    "        target_width = int(np.median(widths))\n",
    "    X_resized = []\n",
    "    for x in X:\n",
    "        h, w, c = x.shape\n",
    "        if w < target_width:\n",
    "            pad = np.zeros((h, target_width - w, c), dtype=x.dtype)\n",
    "            x2 = np.concatenate([x, pad], axis=1)\n",
    "        else:\n",
    "            x2 = x[:, :target_width, :]\n",
    "        X_resized.append(x2)\n",
    "    return np.array(X_resized), target_width\n",
    "\n",
    "X, target_width = pad_frames(X)\n",
    "print('After padding, X shape:', X.shape)\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "y_train_cat = utils.to_categorical(y_train, num_classes)\n",
    "y_test_cat = utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Model: Dual-channel CNN -> GRU -> Dense\n",
    "We build a small, well-regularized model that takes `(n_mels, frames, 2)` input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_gru(input_shape, num_classes):\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3,3), padding='same', activation='relu')(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "    x = layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "    # collapse frequency dimension and keep time axis\n",
    "    # current shape (batch, n_mels/4, frames/4, channels)\n",
    "    shape = tf.keras.backend.int_shape(x)\n",
    "    # permute to (batch, time, features)\n",
    "    x = layers.Permute((2,1,3))(x)\n",
    "    x = layers.Reshape((shape[2], shape[1]*shape[3]))(x)\n",
    "    x = layers.Bidirectional(layers.GRU(128, return_sequences=False))(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "model = build_cnn_gru(input_shape, num_classes)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Callbacks & Training\n",
    "We save the best model and use early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(MODEL_DIR, 'best_model.h5')\n",
    "cb = [\n",
    "    callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    validation_split=0.1,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=cb,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Evaluation: test set metrics and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "y_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Save model and label encoder\n",
    "We already saved best weights; optionally save full model and encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(MODEL_DIR, 'full_model.h5'))\n",
    "import joblib\n",
    "joblib.dump(label_encoder, os.path.join(MODEL_DIR, 'label_encoder.pkl'))\n",
    "print('Saved full_model.h5 and label_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps / Tips\n",
    "- For large datasets convert `build_spectrogram_dataset` into a streaming `tf.data.Dataset` pipeline.  \n",
    "- Try data balancing, class weights, or focal loss for imbalanced classes.  \n",
    "- Experiment with different spectrogram sizes, delta channels (deltas/delta-deltas), or multimodal (text) fusion.  \n",
    "- Use cross-validation and keep experiments reproducible (seed RNGs, log hyperparams)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
