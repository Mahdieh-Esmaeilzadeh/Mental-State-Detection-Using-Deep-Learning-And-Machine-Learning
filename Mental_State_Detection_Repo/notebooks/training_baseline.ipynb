{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Baseline Notebook\n",
    "\n",
    "This notebook implements **Mental State Detection from Speech**.\n",
    "\n",
    "It includes:\n",
    "- Data loading & augmentation\n",
    "- Feature extraction (MFCC, spectral, pitch, ZCR, RMS)\n",
    "- Baseline models (Random Forest, MLP)\n",
    "- Evaluation (Confusion Matrix, ROC, F1-score)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, warnings\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import librosa, soundfile as sf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_audio(y, sr):\n",
    "    fn = random.choice(['pitch', 'stretch', 'noise', 'shift'])\n",
    "    if fn == 'pitch':\n",
    "        n_steps = random.uniform(-3, 3)\n",
    "        return librosa.effects.pitch_shift(y, sr, n_steps=n_steps)\n",
    "    elif fn == 'stretch':\n",
    "        rate = random.uniform(0.85, 1.15)\n",
    "        return librosa.effects.time_stretch(y, rate)\n",
    "    elif fn == 'noise':\n",
    "        noise_amp = 0.005 * np.random.uniform() * np.max(np.abs(y))\n",
    "        return y + noise_amp * np.random.normal(size=y.shape[0])\n",
    "    elif fn == 'shift':\n",
    "        shift = int(np.random.uniform(-0.1, 0.1) * sr)\n",
    "        return np.roll(y, shift)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(y, sr=16000, n_mfcc=13):\n",
    "    feats = []\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    feats.extend(np.mean(mfcc, axis=1))\n",
    "    feats.extend(np.std(mfcc, axis=1))\n",
    "    feats.append(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)))\n",
    "    feats.append(np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)))\n",
    "    feats.append(np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)))\n",
    "    feats.append(np.mean(librosa.feature.zero_crossing_rate(y)))\n",
    "    feats.append(np.mean(librosa.feature.rms(y=y)))\n",
    "    return np.array(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Dataset & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/processed\"  # Adjust to your dataset\n",
    "\n",
    "X, y = [], []\n",
    "for root, dirs, files in os.walk(DATA_PATH):\n",
    "    label = os.path.basename(root)\n",
    "    for f in files:\n",
    "        if f.endswith(\".wav\"):\n",
    "            try:\n",
    "                y_audio, sr = librosa.load(os.path.join(root, f), sr=16000)\n",
    "                feats = extract_features(y_audio, sr)\n",
    "                X.append(feats)\n",
    "                y.append(label)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "X = np.array(X)\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "print(\"Dataset shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# MLP\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(128,64), max_iter=500, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, model_name):\n",
    "    print(f\"\\nModel: {model_name}\\n\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.show()\n",
    "\n",
    "evaluate(y_test, y_pred_rf, \"Random Forest\")\n",
    "evaluate(y_test, y_pred_mlp, \"MLP\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

