# mental-state-detection-using-deep-learning-and-machin-learning

Mental State Detection from Speech

This repository contains the implementation and research materials for a project focused on detecting mental and emotional states from human speech using machine learning and deep learning techniques.

Key features of the project:

ğŸ™ï¸ Speech Emotion Recognition (SER): Extraction of emotional cues from audio signals.

ğŸ§ª Feature Engineering: MFCCs, spectral features, zero-crossing rate, RMS, and pitch.

ğŸ”„ Data Augmentation: Pitch shifting, noise addition, time-stretching, and shifting to improve model robustness.

ğŸ¤– Models: Traditional ML (Random Forest, MLP) and deep learning approaches (CNN, RNN, GRU, dual-channel spectrograms, bimodal fusion).

ğŸ“Š Evaluation: Confusion matrices, ROC curves, cross-validation, and feature importance analysis.

ğŸ“š Documentation & Reports: Literature review, experiments, and thesis-related resources.

The goal of this project is to explore how voice characteristics can reveal a speakerâ€™s emotional and mental state, contributing to advancements in affective computing, humanâ€“computer interaction, and mental health analysis.
