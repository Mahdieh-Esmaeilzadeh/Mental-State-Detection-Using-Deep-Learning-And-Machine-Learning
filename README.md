# mental-state-detection-using-deep-learning-and-machin-learning

Mental State Detection from Speech

This repository contains the implementation and research materials for a project focused on detecting mental and emotional states from human speech using machine learning and deep learning techniques.

Key features of the project:

🎙️ Speech Emotion Recognition (SER): Extraction of emotional cues from audio signals.

🧪 Feature Engineering: MFCCs, spectral features, zero-crossing rate, RMS, and pitch.

🔄 Data Augmentation: Pitch shifting, noise addition, time-stretching, and shifting to improve model robustness.

🤖 Models: Traditional ML (Random Forest, MLP) and deep learning approaches (CNN, RNN, GRU, dual-channel spectrograms, bimodal fusion).

📊 Evaluation: Confusion matrices, ROC curves, cross-validation, and feature importance analysis.

📚 Documentation & Reports: Literature review, experiments, and thesis-related resources.

The goal of this project is to explore how voice characteristics can reveal a speaker’s emotional and mental state, contributing to advancements in affective computing, human–computer interaction, and mental health analysis.
